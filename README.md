# Speech-Understanding-Assignment-2
# Multi-Speaker Speech Separation and Identification

This project implements a joint model for **speech separation** and **speaker identification** using **SpeechBrain's SepFormer** and **UniSpeech-SAT**. The model separates mixed speech signals and identifies the speakers using deep learning techniques.

## Requirements

To run this project, install the following dependencies:

```bash
pip install torch torchaudio speechbrain pesq s3prl mir_eval matplotlib
